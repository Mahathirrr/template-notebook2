{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Analisis Sentimen Komentar YouTube terhadap Kebijakan Pemerintahan\n",
                "\n",
                "Notebook ini berisi proses pengumpulan dan analisis komentar YouTube terkait kebijakan pemerintahan. Proses meliputi:\n",
                "1. Pengumpulan data komentar dari YouTube menggunakan YouTube Data API\n",
                "2. Preprocessing data komentar\n",
                "3. Analisis sentimen dan visualisasi hasil"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Import Library yang Dibutuhkan"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "source": [
                "import urllib.request\n",
                "import urllib.parse\n",
                "import json\n",
                "import csv\n",
                "import time\n",
                "import random\n",
                "import ssl\n",
                "import pandas as pd\n",
                "import numpy as np\n",
                "import re\n",
                "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
                "from Sastrawi.StopWordRemover.StopWordRemoverFactory import StopWordRemoverFactory"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Konfigurasi API dan Fungsi Pengumpulan Data"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "source": [
                "# Bypass SSL certificate verification\n",
                "ssl._create_default_https_context = ssl._create_unverified_context\n",
                "\n",
                "# API Key Configuration\n",
                "API_KEY = \"AIzaSyBJYCAwEeCM0fFCTtqURETBDXGM7oGUg8o\""
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "source": [
                "def get_video_ids(query, max_results=50):\n",
                "    \"\"\"Mendapatkan daftar video ID berdasarkan query pencarian\"\"\"\n",
                "    base_search_url = \"https://www.googleapis.com/youtube/v3/search\"\n",
                "    video_ids = []\n",
                "    \n",
                "    params = {\n",
                "        \"part\": \"snippet\",\n",
                "        \"q\": query,\n",
                "        \"key\": API_KEY,\n",
                "        \"maxResults\": max_results,\n",
                "        \"type\": \"video\",\n",
                "    }\n",
                "\n",
                "    search_url = f\"{base_search_url}?{urllib.parse.urlencode(params)}\"\n",
                "\n",
                "    try:\n",
                "        with urllib.request.urlopen(search_url) as response:\n",
                "            search_results = json.loads(response.read().decode())\n",
                "\n",
                "        for item in search_results.get(\"items\", []):\n",
                "            video_ids.append(item[\"id\"][\"videoId\"])\n",
                "\n",
                "    except Exception as e:\n",
                "        print(f\"Error dalam pencarian video: {e}\")\n",
                "\n",
                "    return video_ids"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "source": [
                "def clean_text(text):\n",
                "    \"\"\"Membersihkan teks komentar\"\"\"\n",
                "    text = text.replace(\"\\n\", \" \").replace(\"\\r\", \" \").replace(\"\\t\", \" \")\n",
                "    text = \" \".join(text.split())\n",
                "    return text\n",
                "\n",
                "class CommentWriter:\n",
                "    def __init__(self, filename):\n",
                "        self.filename = filename\n",
                "        self.comment_count = 0\n",
                "        \n",
                "        with open(self.filename, \"w\", newline=\"\", encoding=\"utf-8\") as file:\n",
                "            writer = csv.writer(file)\n",
                "            writer.writerow([\"Comment\", \"Likes\", \"Timestamp\", \"Video ID\", \"Query\"])\n",
                "\n",
                "    def write_comment(self, comment, video_id, query):\n",
                "        with open(self.filename, \"a\", newline=\"\", encoding=\"utf-8\") as file:\n",
                "            writer = csv.writer(file)\n",
                "            writer.writerow([\n",
                "                clean_text(comment[\"text\"]),\n",
                "                comment[\"likes\"],\n",
                "                comment[\"timestamp\"],\n",
                "                video_id,\n",
                "                query,\n",
                "            ])\n",
                "            self.comment_count += 1\n",
                "\n",
                "        if self.comment_count % 10 == 0:\n",
                "            print(f\"Progress: {self.comment_count} komentar telah dikumpulkan\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "source": [
                "def get_video_comments(video_id, query, writer, target_comments=200):\n",
                "    \"\"\"Mengambil komentar dari video tertentu dan menulis langsung ke CSV\"\"\"\n",
                "    base_comment_url = \"https://www.googleapis.com/youtube/v3/commentThreads\"\n",
                "    comments_collected = 0\n",
                "    \n",
                "    params = {\n",
                "        \"part\": \"snippet\",\n",
                "        \"videoId\": video_id,\n",
                "        \"key\": API_KEY,\n",
                "        \"maxResults\": 100,\n",
                "        \"textFormat\": \"plainText\",\n",
                "    }\n",
                "\n",
                "    try:\n",
                "        while comments_collected < target_comments:\n",
                "            comment_url = f\"{base_comment_url}?{urllib.parse.urlencode(params)}\"\n",
                "\n",
                "            with urllib.request.urlopen(comment_url) as response:\n",
                "                response_data = json.loads(response.read().decode())\n",
                "\n",
                "            for item in response_data.get(\"items\", []):\n",
                "                comment = {\n",
                "                    \"text\": item[\"snippet\"][\"topLevelComment\"][\"snippet\"][\"textDisplay\"],\n",
                "                    \"likes\": item[\"snippet\"][\"topLevelComment\"][\"snippet\"][\"likeCount\"],\n",
                "                    \"timestamp\": item[\"snippet\"][\"topLevelComment\"][\"snippet\"][\"publishedAt\"],\n",
                "                }\n",
                "                writer.write_comment(comment, video_id, query)\n",
                "                comments_collected += 1\n",
                "\n",
                "                if comments_collected >= target_comments:\n",
                "                    break\n",
                "\n",
                "            if \"nextPageToken\" in response_data and comments_collected < target_comments:\n",
                "                params[\"pageToken\"] = response_data[\"nextPageToken\"]\n",
                "            else:\n",
                "                break\n",
                "\n",
                "            time.sleep(random.uniform(1, 3))\n",
                "\n",
                "    except Exception as e:\n",
                "        print(f\"Error dalam mengambil komentar untuk video {video_id}: {e}\")\n",
                "\n",
                "    return comments_collected"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Pengumpulan Data Komentar"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "source": [
                "# Daftar kata kunci pencarian\n",
                "search_queries = [\n",
                "    \"kebijakan ekonomi presiden prabowo 2025\",\n",
                "    \"kontroversi program sosial presiden prabowo\",\n",
                "    \"reaksi publik terhadap instruksi presiden nomor 1 tahun 2025\",\n",
                "    \"perubahan undang-undang militer di era prabowo\",\n",
                "    \"dampak kebijakan anggaran pemerintah prabowo terhadap infrastruktur\",\n",
                "    \"tanggapan masyarakat atas program makan gratis nasional\",\n",
                "    \"pro dan kontra kebijakan penyimpanan devisa hasil ekspor\",\n",
                "    \"kontroversi keterlibatan militer dalam pemerintahan prabowo\",\n",
                "    \"reaksi pasar terhadap kebijakan ekonomi presiden prabowo\",\n",
                "    \"kritik terhadap pemotongan anggaran kementerian di era prabowo\",\n",
                "]\n",
                "\n",
                "output_file = \"youtube_comments.csv\"\n",
                "writer = CommentWriter(output_file)\n",
                "target_total_comments = 10000\n",
                "comments_per_video = 200\n",
                "\n",
                "print(\"Memulai proses pengumpulan data...\")\n",
                "\n",
                "for query in search_queries:\n",
                "    if writer.comment_count >= target_total_comments:\n",
                "        break\n",
                "\n",
                "    print(f\"\\nMencari video untuk query: {query}\")\n",
                "    video_ids = get_video_ids(query)\n",
                "\n",
                "    for video_id in video_ids:\n",
                "        if writer.comment_count >= target_total_comments:\n",
                "            break\n",
                "\n",
                "        print(f\"Mengambil komentar dari video: {video_id}\")\n",
                "        comments_collected = get_video_comments(\n",
                "            video_id,\n",
                "            query,\n",
                "            writer,\n",
                "            min(comments_per_video, target_total_comments - writer.comment_count),\n",
                "        )\n",
                "\n",
                "        time.sleep(random.uniform(2, 5))\n",
                "\n",
                "print(f\"\\nBerhasil mengumpulkan {writer.comment_count} komentar!\")\n",
                "print(f\"Data tersimpan di: {output_file}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Preprocessing Data\n",
                "\n",
                "Tahap preprocessing meliputi:\n",
                "1. Case folding\n",
                "2. Pembersihan teks (URL, mention, hashtag, dll)\n",
                "3. Penghapusan stopwords\n",
                "4. Stemming"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "source": [
                "# Baca data dari CSV\n",
                "df = pd.read_csv('youtube_comments.csv')\n",
                "print(f\"Jumlah data sebelum preprocessing: {len(df)}\")\n",
                "df.head()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "source": [
                "def preprocess_text(text):\n",
                "    \"\"\"Fungsi untuk melakukan preprocessing pada teks komentar\"\"\"\n",
                "    # Case folding\n",
                "    text = text.lower()\n",
                "    \n",
                "    # Hapus URL\n",
                "    text = re.sub(r'http\\S+|www.\\S+', '', text)\n",
                "    \n",
                "    # Hapus mention dan hashtag\n",
                "    text = re.sub(r'@\\w+|#\\w+', '', text)\n",
                "    \n",
                "    # Hapus karakter khusus dan angka\n",
                "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
                "    \n",
                "    # Hapus multiple spaces\n",
                "    text = re.sub(r'\\s+', ' ', text).strip()\n",
                "    \n",
                "    return text\n",
                "\n",
                "# Inisialisasi stemmer dan stopword remover\n",
                "stemmer = StemmerFactory().create_stemmer()\n",
                "stopword_remover = StopWordRemoverFactory().create_stop_word_remover()\n",
                "\n",
                "# Terapkan preprocessing\n",
                "df['cleaned_comment'] = df['Comment'].apply(preprocess_text)\n",
                "df['no_stopwords'] = df['cleaned_comment'].apply(stopword_remover.remove)\n",
                "df['stemmed'] = df['no_stopwords'].apply(stemmer.stem)\n",
                "\n",
                "# Simpan hasil preprocessing\n",
                "df.to_csv('preprocessed_comments.csv', index=False)\n",
                "print(\"\\nHasil preprocessing telah disimpan ke 'preprocessed_comments.csv'\")\n",
                "\n",
                "# Tampilkan contoh hasil\n",
                "print(\"\\nContoh hasil preprocessing:\")\n",
                "sample_results = df[['Comment', 'cleaned_comment', 'no_stopwords', 'stemmed']].head()\n",
                "print(sample_results)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. Analisis Data\n",
                "\n",
                "Beberapa analisis dasar pada data yang telah dipreprocess:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "source": [
                "# Analisis jumlah kata per komentar\n",
                "df['word_count'] = df['cleaned_comment'].apply(lambda x: len(str(x).split()))\n",
                "\n",
                "print(\"Statistik jumlah kata per komentar:\")\n",
                "print(df['word_count'].describe())\n",
                "\n",
                "# Analisis distribusi likes\n",
                "print(\"\\nStatistik jumlah likes:\")\n",
                "print(df['Likes'].describe())\n",
                "\n",
                "# Analisis berdasarkan query pencarian\n",
                "print(\"\\nDistribusi komentar berdasarkan query pencarian:\")\n",
                "query_distribution = df['Query'].value_counts()\n",
                "print(query_distribution)"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}